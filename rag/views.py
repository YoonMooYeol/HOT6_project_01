from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from langchain_community.document_loaders import DirectoryLoader, JSONLoader
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
import chromadb
from langchain_core.documents import Document
from langchain_community.vectorstores.utils import filter_complex_metadata
from dotenv import load_dotenv
import os
import time
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)
from openai import RateLimitError, APIError
from langchain_core.prompts import ChatPromptTemplate
import re
from .models import JsonFile, Message
from .serializers import MessageSerializer

load_dotenv()

class RagSetupViewSet(APIView):
    BATCH_SIZE = 500

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.client = chromadb.PersistentClient(path="./chroma_db")
        self.processed_utterances = self.load_existing_utterances()

    def is_file_processed(self, file_path):
        """íŒŒì¼ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return JsonFile.objects.filter(file_path=file_path).exists()

    def mark_file_as_processed(self, file_path):
        """íŒŒì¼ì„ ì²˜ë¦¬ë¨ìœ¼ë¡œ í‘œì‹œ"""
        JsonFile.objects.create(file_path=file_path)

    def filter_metadata(self, metadata):
        """None ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ë³µì¡í•œ ë©”íƒ€ë°ì´í„° í•„í„°ë§"""
        filtered = {}
        for key, value in metadata.items():
            if value is None:
                filtered[key] = "none"  # Noneì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            elif isinstance(value, (str, int, float, bool)):
                filtered[key] = value
        return filtered

    @retry(
        retry=retry_if_exception_type((RateLimitError, APIError)),
        stop=stop_after_attempt(5),
        wait=wait_exponential(multiplier=1, min=2, max=30),  # ëŒ€ê¸° ì‹œê°„ë„ ì¡°ì •
        before_sleep=lambda retry_state: print(f"â³ {retry_state.attempt_number}ë²ˆì§¸ ì¬ì‹œë„... {retry_state.outcome.exception()} ë°œìƒ")
    )
    def process_batch(self, docs, vector_store=None, embeddings=None, persist_dir=None):
        try:
            # ë°°ì¹˜ í¬ê¸° ë¡œê¹… ì¶”ê°€
            total_tokens = sum(len(doc.page_content.split()) for doc in docs)
            print(f"ğŸ“¦ í˜„ì¬ ë°°ì¹˜: {len(docs)}ê°œ ë¬¸ì„œ, ì•½ {total_tokens}ê°œ í† í°")
            
            # ê° ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„° í•„í„°ë§
            for doc in docs:
                doc.metadata = self.filter_metadata(doc.metadata)

            if vector_store is None:
                vector_store = Chroma(
                    client=self.client,
                    collection_name="persona_chat",
                    embedding_function=embeddings
                )
            
            vector_store.add_documents(docs)
            return vector_store
            
        except Exception as e:
            print(f"ğŸš¨ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}")
            raise

    def load_single_json(self, file_path):
        """ë‹¨ì¼ JSON íŒŒì¼ ë¡œë“œ ë° ì²˜ë¦¬"""
        try:
            loader = JSONLoader(
                file_path=file_path,
                jq_schema=".utterances[]",
                content_key="text",
                metadata_func=lambda metadata, content: {
                    "persona_id": str(content.get("persona_id", "")),  # None ë°©ì§€ë¥¼ ìœ„í•´ ê¸°ë³¸ê°’ ì„¤ì •
                    "utterance_id": str(content.get("utterance_id", "")),
                    "terminate": bool(content.get("terminate", False)),
                    "category": str(metadata.get("info", {}).get("category", "")),
                    "topic": str(metadata.get("info", {}).get("topic", "")),
                    "file_id": str(metadata.get("info", {}).get("id", "")),
                    "file_name": str(metadata.get("info", {}).get("name", "")),
                    "source_file": str(file_path)
                }
            )
            docs = loader.load()
            print(f"âœ… ì„±ê³µ: {file_path} - {len(docs)}ê°œ ë¬¸ì„œ ë¡œë“œ")
            return docs
        except Exception as e:
            print(f"âŒ ì‹¤íŒ¨: {file_path} - ì—ëŸ¬: {str(e)}")
            return []

    def load_existing_utterances(self):
        """ê¸°ì¡´ ë²¡í„° DBì—ì„œ utterance_id ëª©ë¡ ë¡œë“œ"""
        try:
            collection = self.client.get_collection("persona_chat")
            existing_metadata = collection.get()["metadatas"]
            return {meta["utterance_id"] for meta in existing_metadata if meta and "utterance_id" in meta}
        except:
            return set()

    def filter_new_docs(self, docs):
        """ìƒˆë¡œìš´ ë¬¸ì„œë§Œ í•„í„°ë§"""
        new_docs = []
        for doc in docs:
            utterance_id = doc.metadata.get("utterance_id")
            if utterance_id and utterance_id not in self.processed_utterances:
                self.processed_utterances.add(utterance_id)
                new_docs.append(doc)
        return new_docs

    def post(self, request):
        try:
            data_dir = "data"
            if not os.path.exists(data_dir):
                return Response(
                    {"error": "data ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."},
                    status=status.HTTP_400_BAD_REQUEST
                )

            embeddings = OpenAIEmbeddings()
            
            try:
                vector_store = Chroma(
                    client=self.client,
                    collection_name="persona_chat",
                    embedding_function=embeddings
                )
                print("ğŸ“š ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            except:
                vector_store = None
                print("ğŸ†• ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

            # JSON íŒŒì¼ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬
            all_docs = []
            success_count = 0
            error_count = 0
            skipped_count = 0
            
            print("\nğŸ” JSON íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...")
            for root, _, files in os.walk(data_dir):
                for file in files:
                    if file.endswith('.json'):
                        file_path = os.path.join(root, file)
                        
                        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì¸ì§€ í™•ì¸
                        if self.is_file_processed(file_path):
                            print(f"â© ê±´ë„ˆëœ€: {file_path} - ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼")
                            skipped_count += 1
                            continue

                        docs = self.load_single_json(file_path)
                        if docs:
                            all_docs.extend(docs)
                            success_count += 1
                            self.mark_file_as_processed(file_path)
                        else:
                            error_count += 1

            if not all_docs:
                print("\nâš ï¸ ì²˜ë¦¬í•  ìƒˆë¡œìš´ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return Response({
                    "message": "ì¶”ê°€í•  ìƒˆë¡œìš´ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "skipped_documents": skipped_count,
                    "existing_documents": len(self.processed_utterances)
                })

            print(f"\nğŸ“Š ì²˜ë¦¬ í†µê³„:")
            print(f"- ì„±ê³µ: {success_count} íŒŒì¼")
            print(f"- ì‹¤íŒ¨: {error_count} íŒŒì¼")
            print(f"- ê±´ë„ˆëœ€: {skipped_count} ë¬¸ì„œ")
            print(f"- ìƒˆë¡œìš´ ë¬¸ì„œ ìˆ˜: {len(all_docs)}ê°œ")

            # ë°°ì¹˜ ì²˜ë¦¬
            total_processed = 0
            failed_batches = []
            print("\nğŸ’« ì„ë² ë”© ì²˜ë¦¬ ì‹œì‘...")
            
            for i in range(0, len(all_docs), self.BATCH_SIZE):
                batch = all_docs[i:i + self.BATCH_SIZE]
                batch_start = i
                batch_end = min(i + self.BATCH_SIZE, len(all_docs))
                
                try:
                    print(f"\nğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘... ({batch_start+1}-{batch_end}/{len(all_docs)})")
                    vector_store = self.process_batch(
                        batch, 
                        vector_store, 
                        embeddings
                    )
                    total_processed += len(batch)
                    print(f"âœ… ì§„í–‰ë¥ : {total_processed}/{len(all_docs)} ë¬¸ì„œ ì²˜ë¦¬ë¨")
                    
                    if vector_store:
                        print("ğŸ’¾ ë°ì´í„°ê°€ ìë™ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                except Exception as batch_error:
                    print(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ ({batch_start+1}-{batch_end}): {str(batch_error)}")
                    failed_batches.append((batch_start, batch_end))
                    continue

            if failed_batches:
                print("\nâš ï¸ ì‹¤íŒ¨í•œ ë°°ì¹˜ ëª©ë¡:")
                for start, end in failed_batches:
                    print(f"- {start+1}-{end} ë²”ìœ„ì˜ ë¬¸ì„œ")

            print(f"\nâœ¨ ì‘ì—… ì™„ë£Œ!")
            return Response({
                "message": "ë²¡í„° ìŠ¤í† ì–´ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "new_documents_count": total_processed,
                "skipped_documents": skipped_count,
                "existing_documents": len(self.processed_utterances),
                "success_files": success_count,
                "error_files": error_count,
                "failed_batches": failed_batches
            })
            
        except Exception as e:
            print(f"\nğŸš¨ ì¹˜ëª…ì  ì˜¤ë¥˜: {str(e)}")
            return Response(
                {"error": str(e)},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
            
class RagChatViewSet(APIView):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        self.embeddings = OpenAIEmbeddings()
        self.vector_store = Chroma(
            client=chromadb.PersistentClient(path="./chroma_db"),
            collection_name="persona_chat",
            embedding_function=self.embeddings
        )
        self.retriever = self.vector_store.as_retriever()
        
        # LLM ë° í”„ë¡¬í”„íŠ¸ ì„¤ì • (deprecated ê²½ê³  ìˆ˜ì •)
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",  
            temperature=0.7
        )
        self.prompt = ChatPromptTemplate.from_template(
            """
            1. When responding to my messages, maintain a gentle and non-confrontational tone, as if I am speaking directly. 
               Rephrase my words in a warm and considerate manner to convey emotions and concerns respectfully. 
               Keep responses concise and focused on delivering my intended message.
            2. (Most Important) I am not talking to an AI; I am conversing with my partner. 
               Translate my words into a response of 10 characters or fewer that aligns with the specified tone.
            3. Speak in the following manner: gentle, warm, and considerate.
            4. always speak korean
            5. provide 3 examples of messages that can be used to respond to the user's message
            Question: {question}
            Context: {context}

            Read the user's message and rephrase it according to the specified style in the following format:  
            Response format: "User's message" : "Rephrased message1, Rephrased message2, Rephrased message3"
            
            """
        )

    def post(self, request):
        try:
            # ì…ë ¥ ë©”ì‹œì§€ì™€ ìœ ì € ID í™•ì¸
            message = request.data.get('message')
            user_id = request.data.get('user_id')
            
            if not message:
                return Response(
                    {"error": "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."},
                    status=status.HTTP_400_BAD_REQUEST
                )
                
            if not user_id:
                return Response(
                    {"error": "ìœ ì € IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # ë²¡í„° DBê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
            if not self.vector_store._collection.count():
                return Response(
                    {"error": "ë²¡í„° DBì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì„ë² ë”©í•´ì£¼ì„¸ìš”."},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            docs = self.retriever.invoke(message)
            context = "\n".join([doc.page_content for doc in docs])

            # RAG ì‹¤í–‰
            chain = self.prompt | self.llm
            response = chain.invoke({
                "context": context,
                "question": message
            })

            # ë‹µë³€ ì¶”ì¶œ
            try:
                # ì½œë¡  ì´í›„ì˜ ëª¨ë“  ë”°ì˜´í‘œ ë‚´ìš©ì„ ì¶”ì¶œ
                match = re.search(r':\s*"(.+?)(?:")?$', response.content, re.DOTALL)
                if match:
                    # ëª¨ë“  ë”°ì˜´í‘œë¥¼ ì œê±°í•˜ê³  ì €ì¥
                    translated_message = match.group(1).replace('"', '').strip()
                else:
                    translated_message = response.content.replace('"', '').strip()
            except:
                translated_message = response.content.replace('"', '').strip()

            # ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            message_obj = Message.objects.create(
                user_id=user_id,
                input_content=message,
                output_content=response.content,
                translated_content=translated_message
            )

            return Response({
                "message_id": message_obj.id,  # BigAutoField ID ë°˜í™˜
                "user_id": message_obj.user_id,
                "original_message": message_obj.input_content,
                "translated_message": message_obj.translated_content,
                "full_response": message_obj.output_content,
                "created_at": message_obj.created_at
            }, status=status.HTTP_201_CREATED)  # 201 Created ìƒíƒœ ì½”ë“œ ì‚¬ìš©

        except Exception as e:
            print(f"ğŸš¨ Error: {str(e)}")
            return Response(
                {"error": str(e)},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    def get(self, request):
        return Response({
            "user_id": 1,
            "message": "ì±„íŒ… APIì…ë‹ˆë‹¤. POST ìš”ì²­ì„ í†µí•´ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•´ì£¼ì„¸ìš”. ë”ëŸ¬ìš´ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."
        })
            
class RagSyncViewSet(APIView):
    """í¬ë¡œë§ˆ DBì™€ SQLite DB ë™ê¸°í™”ë¥¼ ìœ„í•œ ViewSet"""
    
    def post(self, request):
        try:
            # í¬ë¡œë§ˆ DB ì—°ê²°
            client = chromadb.PersistentClient(path="./chroma_db")
            try:
                collection = client.get_collection("")
                metadata_list = collection.get()["metadatas"]
                print(f"ğŸ“š í¬ë¡œë§ˆ DBì—ì„œ {len(metadata_list)}ê°œì˜ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            except Exception as e:
                return Response({
                    "error": "í¬ë¡œë§ˆ DBì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "detail": str(e)
                }, status=status.HTTP_400_BAD_REQUEST)

            # ê³ ìœ í•œ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
            processed_files = set()
            for metadata in metadata_list:
                if metadata and "source_file" in metadata:
                    processed_files.add(metadata["source_file"])

            # í˜„ì¬ SQLite DBì— ì €ì¥ëœ íŒŒì¼ ëª©ë¡
            existing_files = set(JsonFile.objects.values_list('file_path', flat=True))

            # ìƒˆë¡œ ì¶”ê°€í•  íŒŒì¼ë“¤
            new_files = processed_files - existing_files

            # SQLite DBì— ìƒˆ íŒŒì¼ë“¤ ì¶”ê°€
            for file_path in new_files:
                JsonFile.objects.create(file_path=file_path)

            return Response({
                "message": "í¬ë¡œë§ˆ DBì™€ SQLite DBê°€ ë™ê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "total_files_in_chroma": len(processed_files),
                "existing_files_in_sqlite": len(existing_files),
                "newly_added_files": len(new_files),
                "new_files": list(new_files)
            })

        except Exception as e:
            print(f"ğŸš¨ ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return Response(
                {"error": str(e)},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
            
